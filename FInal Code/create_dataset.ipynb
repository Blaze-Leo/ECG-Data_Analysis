{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import find_peaks\n",
    "import pyentrp.entropy as ent\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sg\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import correlate\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inititalize paths and if needed add custom SNOMED-CT codes as strings in the custom_disease variable, leave as [] if you want to choose 'disease_count' many top abnormalities from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/mnt/Velocity_Vault/ECG/Data/WFDB\"\n",
    "memmap_path='/mnt/Velocity_Vault/ECG/Dataset/'\n",
    "\n",
    "custom_disease=[]\n",
    "disease_count=7\n",
    "\n",
    "\n",
    "# short_start=12700\n",
    "# short_end=21838\n",
    "# shorter_dataset_size=21838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .hea and .mat files. A set of (hea file, mat file) is considered valid if both have the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Size :  21838\n",
      "HEA Array: 21838\n",
      "MAT Array: 21838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_hea_mat(folder_path):\n",
    "    hea_list = []\n",
    "    mat_list = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is a .hea file\n",
    "        if filename.endswith('.hea'):\n",
    "            # Get the base name without the extension\n",
    "            base_name = filename[:-4]\n",
    "            mat_filename = base_name + '.mat'\n",
    "            \n",
    "            # Check if the corresponding .mat file exists\n",
    "            mat_filepath = os.path.join(folder_path, mat_filename)\n",
    "            if os.path.exists(mat_filepath):\n",
    "                # Add the paths to the respective lists\n",
    "                hea_list.append(os.path.join(folder_path, filename))\n",
    "                mat_list.append(mat_filepath)\n",
    "\n",
    "    return hea_list, mat_list\n",
    "\n",
    "hea_array, mat_array=find_hea_mat(dataset_path)\n",
    "\n",
    "print(\"Full Size : \",len(hea_array))\n",
    "\n",
    "\n",
    "# hea_array=hea_array[short_start:short_end]\n",
    "# mat_array=mat_array[short_start:short_end]\n",
    "\n",
    "print(\"HEA Array:\", len(hea_array))\n",
    "print(\"MAT Array:\",len(mat_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the .hea files as a dictionary containing all the necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_header_file(file_path):\n",
    "    # Initialize a dictionary to store the parsed data\n",
    "    data_dict = {}\n",
    "\n",
    "    # Open and read the .hea file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Parse the first line for general information (ID, sample rate, etc.)\n",
    "    first_line = lines[0].strip()\n",
    "    first_line_parts = first_line.split()\n",
    "    data_dict['Recording_ID'] = first_line_parts[0]\n",
    "    data_dict['Num_Leads'] = int(first_line_parts[1])\n",
    "    data_dict['Sampling_Rate_Hz'] = int(first_line_parts[2])\n",
    "    data_dict['Num_Samples'] = int(first_line_parts[3])\n",
    "\n",
    "    # Parse the subsequent lines for lead-specific information\n",
    "    lead_info = []\n",
    "    for i in range(1, data_dict['Num_Leads'] + 1):\n",
    "        lead_line = lines[i].strip()\n",
    "        lead_parts = lead_line.split()\n",
    "        lead_data = {\n",
    "            'File_Name': lead_parts[0],\n",
    "            'Bit_Depth': lead_parts[1],\n",
    "            'Gain_mV': lead_parts[2],\n",
    "            'ADC_Resolution': int(lead_parts[3]),\n",
    "            'Baseline': int(lead_parts[4]),\n",
    "            'Signal_Offset': int(lead_parts[5]),\n",
    "            'Lead_Type': lead_parts[6]\n",
    "        }\n",
    "        lead_info.append(lead_data)\n",
    "    \n",
    "    data_dict['Leads'] = lead_info\n",
    "\n",
    "    # Parse the last few lines for patient information\n",
    "    patient_info = {}\n",
    "    for line in lines[data_dict['Num_Leads'] + 1:]:\n",
    "        line = line.strip()\n",
    "        if line.startswith('#Age:'):\n",
    "            patient_info['Age'] = line.split(\":\")[1].strip()\n",
    "        elif line.startswith('#Sex:'):\n",
    "            patient_info['Sex'] = line.split(\":\")[1].strip()\n",
    "        elif line.startswith('#Dx:'):\n",
    "            patient_info['Diagnosis_Code'] = line.split(\":\")[1].strip()\n",
    "\n",
    "    data_dict['Patient_Info'] = patient_info\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21838/21838 [00:02<00:00, 7810.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21837/21837 [00:00<00:00, 254224.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "hea_dict=[]\n",
    "\n",
    "for i in tqdm(range(len(hea_array))):\n",
    "    if hea_array[i]==None:\n",
    "        continue\n",
    "    hea_dict.append(parse_header_file(hea_array[i]))\n",
    "    \n",
    "print(len(hea_dict))\n",
    "# pprint(hea_dict)\n",
    "\n",
    "disease_dict=[]\n",
    "\n",
    "for i in tqdm(range(len(hea_dict))):\n",
    "    disease_dict.append((hea_dict[i][\"Patient_Info\"][\"Diagnosis_Code\"]).split(','))\n",
    "    \n",
    "print(len(disease_dict))\n",
    "# pprint(disease_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows the occurance of each abnormalities in descending order and chooses the abnormalities that are going to be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Abnormalities found in Dataset :  50 \n",
      "\n",
      "Dx: 426783006, Occurrences: 18092\n",
      "Dx: 164865005, Occurrences: 5261\n",
      "Dx: 39732003, Occurrences: 5146\n",
      "Dx: 164951009, Occurrences: 3389\n",
      "Dx: 164873001, Occurrences: 2359\n",
      "Dx: 164934002, Occurrences: 2345\n",
      "Dx: 164861001, Occurrences: 2175\n",
      "Dx: 445118002, Occurrences: 1626\n",
      "Dx: 164889003, Occurrences: 1514\n",
      "Dx: 164884008, Occurrences: 1154\n",
      "Dx: 713426002, Occurrences: 1118\n",
      "Dx: 429622005, Occurrences: 1009\n",
      "Dx: 427084000, Occurrences: 826\n",
      "Dx: 270492004, Occurrences: 797\n",
      "Dx: 698252002, Occurrences: 789\n",
      "Dx: 427393009, Occurrences: 772\n",
      "Dx: 55930002, Occurrences: 770\n",
      "Dx: 426177001, Occurrences: 637\n",
      "Dx: 164917005, Occurrences: 548\n",
      "Dx: 713427006, Occurrences: 542\n",
      "Dx: 164909002, Occurrences: 536\n",
      "Dx: 67741000119109, Occurrences: 427\n",
      "Dx: 284470004, Occurrences: 398\n",
      "Dx: 428750005, Occurrences: 381\n",
      "Dx: 54329005, Occurrences: 354\n",
      "Dx: 47665007, Occurrences: 343\n",
      "Dx: 164947007, Occurrences: 340\n",
      "Dx: 10370003, Occurrences: 296\n",
      "Dx: 59931005, Occurrences: 294\n",
      "Dx: 425419005, Occurrences: 219\n",
      "Dx: 251146004, Occurrences: 182\n",
      "Dx: 445211001, Occurrences: 177\n",
      "Dx: 63593006, Occurrences: 157\n",
      "Dx: 251200008, Occurrences: 156\n",
      "Dx: 425623009, Occurrences: 142\n",
      "Dx: 89792004, Occurrences: 126\n",
      "Dx: 111975006, Occurrences: 118\n",
      "Dx: 446358003, Occurrences: 99\n",
      "Dx: 11157007, Occurrences: 82\n",
      "Dx: 74390002, Occurrences: 80\n",
      "Dx: 251120003, Occurrences: 77\n",
      "Dx: 164890007, Occurrences: 73\n",
      "Dx: 426434006, Occurrences: 44\n",
      "Dx: 266249003, Occurrences: 30\n",
      "Dx: 164931005, Occurrences: 28\n",
      "Dx: 426761007, Occurrences: 27\n",
      "Dx: 67198005, Occurrences: 24\n",
      "Dx: 251180001, Occurrences: 20\n",
      "Dx: 27885002, Occurrences: 16\n",
      "Dx: 195042002, Occurrences: 14\n",
      "Chosen Diseases :  ['426783006', '164865005', '39732003', '164951009', '164873001', '164934002', '164861001']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "flattened_list = [number for sublist in disease_dict for number in sublist]\n",
    "occurrences = Counter(flattened_list)\n",
    "\n",
    "print(\"Number of Abnormalities found in Dataset : \",len(occurrences),\"\\n\")\n",
    "\n",
    "occurrences = occurrences.most_common()\n",
    "\n",
    "# Display the occurrences\n",
    "for number, count in occurrences:\n",
    "    print(f\"Dx: {number}, Occurrences: {count}\")\n",
    "\n",
    "\n",
    "chosen_disease=[number for number,_ in occurrences[:disease_count]]\n",
    "\n",
    "if len(custom_disease)!=0:\n",
    "    chosen_disease=custom_disease\n",
    "\n",
    "print(\"Chosen Diseases : \",chosen_disease)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pan Tompkins Algorithm approach of converting raw ECG signals into moving window signals so that r_peaks, p_peaks, t_peaks can be detected efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pan_Tompkins_QRS:\n",
    "    def __init__(self, fs):\n",
    "        self.fs = fs  # Sampling frequency (fs) passed as an argument\n",
    "\n",
    "    def band_pass_filter(self, signal):\n",
    "        result = None\n",
    "        sig = signal.copy()\n",
    "\n",
    "        # Low-pass filter (11 Hz cutoff)\n",
    "        for index in range(len(signal)):\n",
    "            sig[index] = signal[index]\n",
    "            if (index >= 1):\n",
    "                sig[index] += 2*sig[index-1]\n",
    "            if (index >= 2):\n",
    "                sig[index] -= sig[index-2]\n",
    "            if (index >= 6):\n",
    "                sig[index] -= 2*signal[index-6]\n",
    "            if (index >= 12):\n",
    "                sig[index] += signal[index-12]\n",
    "\n",
    "        result = sig.copy()\n",
    "\n",
    "        # High-pass filter (5 Hz cutoff)\n",
    "        for index in range(len(signal)):\n",
    "            result[index] = -1*sig[index]\n",
    "            if (index >= 1):\n",
    "                result[index] -= result[index-1]\n",
    "            if (index >= 16):\n",
    "                result[index] += 32*sig[index-16]\n",
    "            if (index >= 32):\n",
    "                result[index] += sig[index-32]\n",
    "\n",
    "        # Normalize the result\n",
    "        max_val = max(max(result), -min(result))\n",
    "        result = result / max_val\n",
    "        return result\n",
    "\n",
    "    def derivative(self, signal):\n",
    "        result = signal.copy()\n",
    "        for index in range(len(signal)):\n",
    "            result[index] = 0\n",
    "            if (index >= 1):\n",
    "                result[index] -= 2*signal[index-1]\n",
    "            if (index >= 2):\n",
    "                result[index] -= signal[index-2]\n",
    "            if (index >= 2 and index <= len(signal)-2):\n",
    "                result[index] += 2*signal[index+1]\n",
    "            if (index >= 2 and index <= len(signal)-3):\n",
    "                result[index] += signal[index+2]\n",
    "            result[index] = (result[index] * self.fs) / 8  # Use self.fs instead of annotation.fs\n",
    "        return result\n",
    "\n",
    "    def squaring(self, signal):\n",
    "        result = signal.copy()\n",
    "        for index in range(len(signal)):\n",
    "            result[index] = signal[index]**2\n",
    "        return result\n",
    "\n",
    "    def moving_window_integration(self, signal):\n",
    "        result = signal.copy()\n",
    "        win_size = round(0.150 * self.fs)\n",
    "\n",
    "        # If the signal length is smaller than the win_size, use the signal length\n",
    "        if len(signal) < win_size:\n",
    "            win_size = len(signal)\n",
    "\n",
    "        sum = 0\n",
    "        for j in range(win_size):\n",
    "            sum += signal[j] / win_size\n",
    "            result[j] = sum\n",
    "\n",
    "        for index in range(win_size, len(signal)):\n",
    "            sum += signal[index] / win_size\n",
    "            sum -= signal[index - win_size] / win_size\n",
    "            result[index] = sum\n",
    "\n",
    "        return result\n",
    "\n",
    "    def solve(self, signal):\n",
    "        input_signal = signal.iloc[:, 1].to_numpy()\n",
    "\n",
    "        # Bandpass Filter\n",
    "        bpass = self.band_pass_filter(input_signal.copy())\n",
    "\n",
    "        # Derivative Function\n",
    "        der = self.derivative(bpass.copy())\n",
    "\n",
    "        # Squaring Function\n",
    "        sqr = self.squaring(der.copy())\n",
    "\n",
    "        # Moving Window Integration Function\n",
    "        mwin = self.moving_window_integration(sqr.copy())\n",
    "\n",
    "        return mwin\n",
    "\n",
    "\n",
    "# Update process_ecg to adjust signal using Signal_Offset and Gain_mV from hea_dict\n",
    "def preprocess_ecg(hea_dict, raw_ecg):\n",
    "    #return raw_ecg\n",
    "    # Create a dictionary of offsets and gains for each lead\n",
    "    leads_info = hea_dict['Leads']\n",
    "    \n",
    "    processed_signals = []\n",
    "    \n",
    "    for i, lead in enumerate(leads_info):\n",
    "        signal_offset = lead['Signal_Offset']\n",
    "        gain_mv = int(lead['Gain_mV'].replace(\"/mv\", \"\"))  # Gain in mV\n",
    "        \n",
    "        # Adjust the raw ECG signal for this lead by applying offset and gain\n",
    "        adjusted_signal = (raw_ecg[i] + signal_offset) * gain_mv / 1000  # Scale to mV\n",
    "        \n",
    "        processed_signals.append(adjusted_signal)\n",
    "    \n",
    "    return processed_signals\n",
    "\n",
    "def process_ecg(hea_dict, signal):\n",
    "    # Load the .mat ECG signal data\n",
    "    # Preprocess the ECG signals using the header information\n",
    "    processed_signals = preprocess_ecg(hea_dict, signal)\n",
    "\n",
    "    # Extract fs (sampling frequency) from the header\n",
    "    fs = hea_dict['Sampling_Rate_Hz']  # Assuming it's present in the header file\n",
    "    #print(\"Fs : \",fs)\n",
    "    # Initialize QRS detector with fs\n",
    "    QRS_detector = Pan_Tompkins_QRS(fs)\n",
    "\n",
    "    # Solve using Pan-Tompkins algorithm for all signals\n",
    "    processed_signals_qrs = [QRS_detector.solve(pd.DataFrame({'Time': range(len(signal)), 'ECG': signal})) for signal in processed_signals]\n",
    "\n",
    "    return processed_signals_qrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to calculate the wide features of an ECG signal - Age, Gender (Male:0, Female:1), Max HR, Mean HR, Min HR, P wave correlation coefficient, RMSSD, RR interval (Mean), RR interval (Median), RR interval Fisher information, T wave permutation entropy (Median), T wave permutation entropy (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_mat_file(mat_path):\n",
    "    # Load the .mat file using scipy.io\n",
    "    mat_data = scipy.io.loadmat(mat_path)\n",
    "    # Assuming the ECG signal is stored in 'ecg' key or similar\n",
    "    ecg_signal = mat_data['val']  # Replace 'ecg' with the actual key if different\n",
    "    return ecg_signal\n",
    "\n",
    "def calculate_rr_intervals(r_peaks, samp_freq):\n",
    "    \"\"\"\n",
    "    Calculate RR intervals (differences between successive R-peaks).\n",
    "    \n",
    "    :param r_peaks: List or array of R-peak positions (indices).\n",
    "    :param samp_freq: Sampling frequency of the ECG signal (in Hz).\n",
    "    :return: List of RR intervals in milliseconds.\n",
    "    \"\"\"\n",
    "    # Calculate the differences between successive R-peaks (in samples)\n",
    "    rr_intervals_samples = np.diff(r_peaks)\n",
    "    \n",
    "    # Convert RR intervals from samples to milliseconds\n",
    "    rr_intervals_ms = rr_intervals_samples / samp_freq * 1000  # Multiply by 1000 to convert to ms\n",
    "    \n",
    "    return rr_intervals_ms\n",
    "\n",
    "def compute_mpe(signal, m, delay, scales):\n",
    "    \"\"\"\n",
    "    Compute Multiscale Permutation Entropy (MPE) for a given signal.\n",
    "    \n",
    "    :param signal: 1D array or list of signal values.\n",
    "    :param m: Embedding dimension for PE.\n",
    "    :param delay: Time delay for PE.\n",
    "    :param scales: List of scales for multiscale PE calculation.\n",
    "    :return: List of MPE values for each scale.\n",
    "    \"\"\"\n",
    "    mpe_values = []\n",
    "    for scale in scales:\n",
    "        # Coarse-grain the signal for the current scale\n",
    "        coarse_grained = np.mean(signal[:len(signal)//scale * scale].reshape(-1, scale), axis=1)\n",
    "        # Compute Permutation Entropy for the coarse-grained signal\n",
    "        mpe_values.append(ent.permutation_entropy(coarse_grained, order=m, delay=delay))\n",
    "    return mpe_values\n",
    "\n",
    "def t_wave_mpe(ecg_signal, t_peaks, fs=500, window_size=0.2, m=3, delay=1, scales=[1, 2, 3, 4, 5]):\n",
    "    \"\"\"\n",
    "    Compute T-wave Multiscale Permutation Entropy (MPE) for an ECG signal.\n",
    "    \n",
    "    :param ecg_signal: The ECG signal (array or list).\n",
    "    :param t_peaks: List of indices of T-peaks in the ECG signal.\n",
    "    :param fs: Sampling frequency of the signal (in Hz).\n",
    "    :param window_size: Time window around T-peak to extract T-wave (in seconds).\n",
    "    :param m: Embedding dimension for PE.\n",
    "    :param delay: Time delay for PE.\n",
    "    :param scales: List of scales for multiscale PE calculation.\n",
    "    :return: List of MPE values for each T-wave segment.\n",
    "    \"\"\"\n",
    "    t_wave_mpe_values = []\n",
    "    half_window_samples = int(window_size * fs / 2)  # Half-window size in samples\n",
    "    \n",
    "    for t_peak in t_peaks:\n",
    "        # Define the window around the T-peak\n",
    "        start_idx = max(0, t_peak - half_window_samples)\n",
    "        end_idx = min(len(ecg_signal), t_peak + half_window_samples)\n",
    "        \n",
    "        # Extract the T-wave segment\n",
    "        t_wave_segment = ecg_signal[start_idx:end_idx]\n",
    "        \n",
    "        # Resample the segment to a fixed length (if needed)\n",
    "        if len(t_wave_segment) != 2 * half_window_samples:\n",
    "            t_wave_segment = np.pad(\n",
    "                t_wave_segment, \n",
    "                (0, 2 * half_window_samples - len(t_wave_segment)), \n",
    "                'constant'\n",
    "            )\n",
    "        \n",
    "        # Calculate Multiscale Permutation Entropy for the T-wave segment\n",
    "        mpe_values = compute_mpe(t_wave_segment, m=m, delay=delay, scales=scales)\n",
    "        t_wave_mpe_values.append(mpe_values)\n",
    "    \n",
    "    return np.std(t_wave_mpe_values),np.mean(t_wave_mpe_values)\n",
    "\n",
    "def calculate_rr(rr_intervals):\n",
    "    \"\"\"\n",
    "    Calculate the RMSSD (Root Mean Square of Successive Differences) from RR intervals.\n",
    "\n",
    "    :param rr_intervals: List or array of RR intervals in milliseconds.\n",
    "    :return: RMSSD value.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(rr_intervals)==0:\n",
    "        return 0.0,0.0,0.0\n",
    "    \n",
    "    # Calculate successive differences of RR intervals\n",
    "    diff_rr = np.diff(rr_intervals)\n",
    "    \n",
    "    # Square the differences\n",
    "    squared_diff_rr = diff_rr ** 2\n",
    "    \n",
    "    # Calculate the mean of the squared differences\n",
    "    mean_squared_diff = np.mean(squared_diff_rr)\n",
    "    \n",
    "    # Return the square root of the mean\n",
    "    rmssd = np.sqrt(mean_squared_diff)\n",
    "    rrmed=np.median(diff_rr)\n",
    "    rrmin=np.min(diff_rr)\n",
    "    return rmssd,rrmed,rrmin\n",
    "\n",
    "def find_p_peaks(ecg_signal, r_peaks, sampling_rate=500, p_wave_window=150):\n",
    "    \"\"\"\n",
    "    Detect P-peaks in an ECG signal based on R-peak locations.\n",
    "\n",
    "    :param ecg_signal: 1D array or list of the ECG signal.\n",
    "    :param r_peaks: List of R-peak indices.\n",
    "    :param sampling_rate: Sampling rate of the ECG signal in Hz.\n",
    "    :param p_wave_window: Time window before each R-peak to search for P-peaks (in ms).\n",
    "    :return: List of P-peak indices.\n",
    "    \"\"\"\n",
    "    # Convert the P-wave window from ms to samples\n",
    "    p_wave_window_samples = int((p_wave_window / 1000) * sampling_rate)\n",
    "    p_peaks = []\n",
    "\n",
    "    for r_peak in r_peaks:\n",
    "        # Define the P-wave search region (before the R-peak)\n",
    "        start_idx = max(0, r_peak - p_wave_window_samples)\n",
    "        end_idx = r_peak\n",
    "\n",
    "        # Extract the segment of the signal for P-wave detection\n",
    "        p_wave_region = ecg_signal[start_idx:end_idx]\n",
    "\n",
    "        # Detect peaks in the P-wave region\n",
    "        peaks, _ = find_peaks(p_wave_region)\n",
    "\n",
    "        if len(peaks) > 0:\n",
    "            # Find the peak with the maximum amplitude (assume it corresponds to the P-wave)\n",
    "            p_peak_idx = peaks[np.argmax(p_wave_region[peaks])]\n",
    "            p_peaks.append(start_idx + p_peak_idx)\n",
    "\n",
    "    return p_peaks\n",
    "\n",
    "def find_t_peaks(ecg_signal, r_peaks, fs=500, t_window=(0.15, 0.4)):\n",
    "    \"\"\"\n",
    "    Find T-peaks in an ECG signal.\n",
    "\n",
    "    :param ecg_signal: The ECG signal (array or list).\n",
    "    :param r_peaks: Indices of detected R-peaks.\n",
    "    :param fs: Sampling frequency of the signal (in Hz).\n",
    "    :param t_window: Time window after R-peaks to search for T-peaks (in seconds).\n",
    "    :return: List of indices of T-peaks.\n",
    "    \"\"\"\n",
    "    t_peaks = []\n",
    "    search_start_offset = int(t_window[0] * fs)  # Convert seconds to samples\n",
    "    search_end_offset = int(t_window[1] * fs)    # Convert seconds to samples\n",
    "\n",
    "    for r_peak in r_peaks:\n",
    "        # Define the search window for the T-wave\n",
    "        search_start = r_peak + search_start_offset\n",
    "        search_end = r_peak + search_end_offset\n",
    "\n",
    "        # Ensure the search window is within signal bounds\n",
    "        if search_start >= len(ecg_signal) or search_end > len(ecg_signal):\n",
    "            break\n",
    "\n",
    "        # Extract the segment where the T-wave is expected\n",
    "        t_wave_segment = ecg_signal[search_start:search_end]\n",
    "\n",
    "        # Find the index of the maximum amplitude in the segment\n",
    "        t_peak_relative = np.argmax(t_wave_segment)\n",
    "        t_peak = search_start + t_peak_relative\n",
    "\n",
    "        t_peaks.append(t_peak)\n",
    "\n",
    "    return t_peaks\n",
    "\n",
    "def compute_p_wave_correlation(ecg_signal, p_peaks, window_size=50):\n",
    "    \"\"\"\n",
    "    Compute the P-wave correlation coefficient between individual P-waves and the template P-wave.\n",
    "\n",
    "    :param ecg_signal: The ECG signal (array or list).\n",
    "    :param p_peaks: List of P-peak indices.\n",
    "    :param window_size: The window size around each P-peak to define the P-wave (in samples).\n",
    "    :return: List of correlation coefficients for each P-wave with the template P-wave.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract P-wave segments\n",
    "    p_waves = []\n",
    "    for p_peak in p_peaks:\n",
    "        start_idx = max(0, p_peak - window_size // 2)\n",
    "        end_idx = min(len(ecg_signal), p_peak + window_size // 2)\n",
    "        p_wave = ecg_signal[start_idx:end_idx]\n",
    "        \n",
    "        # Zero-pad if the segment size is smaller than the window size\n",
    "        if len(p_wave) < window_size:\n",
    "            p_wave = np.pad(p_wave, (0, window_size - len(p_wave)), mode='constant')\n",
    "        \n",
    "        p_waves.append(p_wave)\n",
    "    \n",
    "    # Step 2: Compute the template P-wave (average of all P-waves)\n",
    "    p_wave_template = np.mean(p_waves, axis=0)\n",
    "    \n",
    "    # Step 3: Compute correlation coefficients\n",
    "    correlation_coefficients = []\n",
    "    for p_wave in p_waves:\n",
    "        if np.all(p_wave == p_wave[0]):\n",
    "            corr=0\n",
    "        else:\n",
    "            corr, _ = pearsonr(p_wave, p_wave_template)\n",
    "            \n",
    "        correlation_coefficients.append(corr)\n",
    "    \n",
    "    return np.mean(correlation_coefficients)\n",
    "\n",
    "def calculate_rr_fisher_information(rr_intervals):\n",
    "    \"\"\"\n",
    "    Calculate the Fisher Information for the mean of the RR intervals.\n",
    "    \n",
    "    The Fisher Information for the mean of a normal distribution is given by:\n",
    "        Fisher Information = 1 / variance\n",
    "    \n",
    "    :param rr_intervals: List or array of RR intervals in milliseconds.\n",
    "    :return: Fisher Information value.\n",
    "    \"\"\"\n",
    "    # Calculate the variance of the RR intervals\n",
    "    variance = np.var(rr_intervals)\n",
    "    \n",
    "    # Fisher Information is the inverse of the variance\n",
    "    fisher_information = 1 / variance if variance > 0 else 0\n",
    "    \n",
    "    return fisher_information\n",
    "\n",
    "def check_gender(s):\n",
    "    s = s.lower()  # Convert the string to lowercase for case-insensitive comparison\n",
    "    if 'male' in s:\n",
    "        return 0\n",
    "    elif 'female' in s:\n",
    "        return 1\n",
    "    else:\n",
    "        return random.choice([0, 1])\n",
    "\n",
    "def check_age(s):\n",
    "    # Try to find an integer in the string\n",
    "    numbers = [int(word) for word in s.split() if word.isdigit()]\n",
    "    \n",
    "    if numbers:\n",
    "        return numbers[0]  # Return the first integer found\n",
    "    else:\n",
    "        return random.randint(20, 95)\n",
    "    \n",
    "def get_10_seconds(signal,fs=500):\n",
    "    sampled=[]\n",
    "    for lead in signal:\n",
    "        sampled.append(get_random_10s_segment(lead,sampling_rate=fs))\n",
    "    return np.array(sampled)\n",
    "        \n",
    "        \n",
    "def get_random_10s_segment(ecg_signal, sampling_rate=500):\n",
    "    # Calculate the number of samples for 15 seconds\n",
    "    num_samples = int(10 * sampling_rate)\n",
    "    \n",
    "    # Check if the signal is shorter than 15 seconds\n",
    "    if len(ecg_signal) < num_samples:\n",
    "        # Apply zero-padding\n",
    "        padded_signal = np.zeros(num_samples)\n",
    "        padded_signal[:len(ecg_signal)] = ecg_signal\n",
    "        return padded_signal\n",
    "    elif len(ecg_signal)==num_samples:\n",
    "        return ecg_signal\n",
    "    else:\n",
    "        return ecg_signal[0:num_samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that loads the signals and returns the raw signals, wide features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_labels(file_index,hea_array,mat_array,valid_disease):\n",
    "    hea_dict=parse_header_file(hea_array[file_index])\n",
    "    signal_org = load_mat_file(mat_array[file_index])\n",
    "    \n",
    "    #print(signal_org.shape)\n",
    "    \n",
    "    disease=(hea_dict[\"Patient_Info\"][\"Diagnosis_Code\"]).split(',')\n",
    "    age=hea_dict[\"Patient_Info\"][\"Age\"]\n",
    "    gender=hea_dict[\"Patient_Info\"][\"Sex\"]\n",
    "    fs = hea_dict['Sampling_Rate_Hz']\n",
    "    \n",
    "    presence=[]\n",
    "    \n",
    "    for dis in valid_disease:\n",
    "        if any(dis.lower() in s.lower() for s in disease):\n",
    "            presence.append(1)\n",
    "        else:\n",
    "            presence.append(0)\n",
    "            \n",
    "    # if presence==[0 for _ in range(len*valid_disease)]:\n",
    "    #     return [],[],[]\n",
    "    \n",
    "    signal_sampled= get_10_seconds(signal_org,fs=fs)\n",
    "    \n",
    "    signal=process_ecg(hea_dict,signal_sampled)\n",
    "    \n",
    "    features=[]\n",
    "    for i in range(len(signal)):\n",
    "        feat=calculate_each_signal(signal[i],fs)\n",
    "        features.append(feat)\n",
    "        \n",
    "    features = list(map(list, zip(*features)))\n",
    "    \n",
    "    classify=[np.mean(fe) for fe in features]\n",
    "    ag=check_age(age)\n",
    "    ge=check_gender(gender)\n",
    "    classify.append(ag)\n",
    "    classify.append(ge)\n",
    "    \n",
    "\n",
    "    \n",
    "    return signal_sampled,classify,presence\n",
    "    \n",
    "def calculate_each_signal(signal,fs):\n",
    "    samp_freq=fs\n",
    "    \n",
    "    r_peaks,_ = find_peaks(signal, distance=200, height=0.5)\n",
    "    r_peaks = np.array(r_peaks)\n",
    "    r_peaks = r_peaks[r_peaks > 0]\n",
    "    \n",
    "    if len(r_peaks)==0:\n",
    "        return [0.0 for _ in range(10)]\n",
    "    \n",
    "    p_peaks = find_p_peaks(signal, r_peaks, sampling_rate=fs)\n",
    "\n",
    "    t_peaks=find_t_peaks(signal,r_peaks, fs=fs)\n",
    "    \n",
    "    r_peaks=r_peaks[1:]\n",
    "    p_peaks=p_peaks[1:]\n",
    "    t_peaks=t_peaks[1:]\n",
    "    \n",
    "    # Calculate the heart rate\n",
    "    h_rates=np.diff(r_peaks)\n",
    "    \n",
    "    \n",
    "    if len(h_rates)==0:\n",
    "        h_mean=0\n",
    "        h_max=0\n",
    "        h_min=0\n",
    "    else:\n",
    "        h_rates=h_rates*2\n",
    "        h_mean = (60*fs)/np.average(h_rates)\n",
    "        h_max= (60*fs)/np.min([x for x in h_rates if x != 0])\n",
    "        h_min = (60*fs)/np.max(h_rates)\n",
    "    \n",
    "    rr_interval=calculate_rr_intervals(r_peaks,samp_freq)\n",
    "    std_mpe,median_mpe=t_wave_mpe(signal, t_peaks)\n",
    "    rmssd,rrmed,rrmin = calculate_rr(r_peaks)\n",
    "    \n",
    "    \n",
    "    p_wave_corrs = compute_p_wave_correlation(signal, p_peaks)\n",
    "    \n",
    "    fisher=calculate_rr_fisher_information(rr_interval)\n",
    "    \n",
    "    features=[h_min,std_mpe,h_max,median_mpe,rmssd,p_wave_corrs,rrmed,h_mean,fisher,rrmin]\n",
    "    features=[0 if (np.isnan(x) or np.isinf(x)) else x for x in features]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some times files may not contain any information or maybe corrupted, those are filtered out here and only valid files are going to be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size :  21837\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_size=min(len(hea_array),len(mat_array))\n",
    "\n",
    "size=0\n",
    "index_dict={}\n",
    "for test_number in range(dataset_size):\n",
    "    if hea_array[test_number]==None:\n",
    "        continue\n",
    "    \n",
    "    # hea_dict=parse_header_file(hea_array[test_number])\n",
    "    # disease=hea_dict[\"Patient_Info\"][\"Diagnosis_Code\"].split(',')\n",
    "    \n",
    "    # presence=False\n",
    "    \n",
    "    # for dis in chosen_disease:\n",
    "    #     if any(dis.lower() in s.lower() for s in disease):\n",
    "    #         presence=True\n",
    "            \n",
    "    # if not presence:\n",
    "    #     continue\n",
    "            \n",
    "    \n",
    "    index_dict[test_number]=size\n",
    "    size+=1\n",
    "    \n",
    "print('Dataset Size : ',size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset within the applicable size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21838/21838 [1:16:47<00:00,  4.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ecg_signal=np.memmap(memmap_path+'ecg_signal', dtype='int16', mode='w+', shape=(size, 12,5000))\n",
    "features=np.memmap(memmap_path+'features', dtype='float32', mode='w+', shape=(size, 12))\n",
    "labels=np.memmap(memmap_path+'labels', dtype='int', mode='w+', shape=(size, len(chosen_disease)))\n",
    "\n",
    "# features=np.zeros((size, 12), dtype=np.float32)\n",
    "# labels=np.zeros((size, len(chosen_disease)), dtype=int)\n",
    "\n",
    "for test_number in tqdm(range(dataset_size)):\n",
    "    if hea_array[test_number]==None:\n",
    "        continue\n",
    "    sig,feat,lab=calculate_labels(test_number,hea_array,mat_array,chosen_disease)\n",
    "    \n",
    "    ecg_signal[index_dict[test_number]]=sig    \n",
    "    features[index_dict[test_number]]=feat\n",
    "    labels[index_dict[test_number]]=lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priniting average features over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Features \n",
      "\n",
      "{'Age': 59.827267,\n",
      " 'Gender (Male:0, Female:1)': 0.0,\n",
      " 'Max HR': 74.05248,\n",
      " 'Mean HR': 55.87401,\n",
      " 'Min HR': 39.076946,\n",
      " 'P wave correlation coefficient': 0.60543877,\n",
      " 'RMSSD': 275.7696,\n",
      " 'RR interval (Mean)': 202.63823,\n",
      " 'RR interval (Median)': 255.66045,\n",
      " 'RR interval Fisher information': 8.3664374e-05,\n",
      " 'T wave permutation entropy (Median)': 1.7843825,\n",
      " 'T wave permutation entropy (STD)': 0.29116395}\n",
      "\n",
      "Average Labels \n",
      "\n",
      "{'164861001': 0.099601593625498,\n",
      " '164865005': 0.24092137198333105,\n",
      " '164873001': 0.1080276594770344,\n",
      " '164934002': 0.10738654577093923,\n",
      " '164951009': 0.15519531071117829,\n",
      " '39732003': 0.2356550808261208,\n",
      " '426783006': 0.8285020836195448}\n"
     ]
    }
   ],
   "source": [
    "average_feature = np.mean(features, axis=0)\n",
    "average_label = np.mean(labels, axis=0)\n",
    "\n",
    "feat_dict_key = ['Min HR', 'T wave permutation entropy (STD)',\n",
    "            'Max HR', 'T wave permutation entropy (Median)', 'RMSSD',\n",
    "            'P wave correlation coefficient', \n",
    "            'RR interval (Median)', 'Mean HR', 'RR interval Fisher information',\n",
    "            'RR interval (Mean)','Age','Gender (Male:0, Female:1)']\n",
    "\n",
    "# Create a dictionary to map feature names to their corresponding values\n",
    "feature_dict = dict(zip(feat_dict_key, average_feature))\n",
    "label_dict = dict(zip(chosen_disease, average_label))\n",
    "\n",
    "print(\"Average Features \\n\")\n",
    "pprint(feature_dict)\n",
    "print(\"\\nAverage Labels \\n\")\n",
    "pprint(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the shapes for future uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21837, 12, 5000)\n",
      "(21837, 12)\n",
      "(21837, 7)\n"
     ]
    }
   ],
   "source": [
    "print(ecg_signal.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
